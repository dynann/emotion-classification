What is RoBERTa (in simple terms)?

RoBERTa is a text-only Transformer model, just like BERT, but stronger and more robust.

Wav2Vec2 â†’ understands audio / speech

RoBERTa â†’ understands text / language

So when I mentioned RoBERTa, I meant:

Use the text (transcriptions) of your utterances to help predict emotion, together with audio.

Why RoBERTa helps Emotion Recognition

Emotion is conveyed by two signals:

How itâ€™s said â†’ prosody, pitch, energy (audio)

What is said â†’ words, semantics (text)

Examples:

â€œIâ€™m fine.â€ ğŸ˜ vs ğŸ˜¡ vs ğŸ˜¢
â†’ audio matters

â€œI hate youâ€ vs â€œThank you so muchâ€
â†’ text matters

Many SER papers show:

Audio-only < Text-only < Audio + Text (multimodal)

Thatâ€™s why RoBERTa is useful.

Where RoBERTa fits in your dataset

Your DatasetDict already has:

"text": "This is the transcription of the utterance"


So you can do:

Wav2Vec2 â†’ extract speech embeddings

RoBERTa â†’ extract text embeddings

Fuse them â†’ predict emotion

What RoBERTa actually does (technical)

RoBERTa takes a sentence and outputs a vector like:

"I am very angry right now"
â†“
768-dimensional embedding


This embedding captures:

sentiment

emotional intensity

semantics

Perfect for SER.

Basic RoBERTa model you would use
from transformers import RobertaTokenizer, RobertaModel

tokenizer = RobertaTokenizer.from_pretrained("roberta-base")
text_model = RobertaModel.from_pretrained("roberta-base")


roberta-base â†’ 768-dim output

Lightweight enough for 8GB GPU

How audio + text are combined (fusion)
1ï¸âƒ£ Late fusion (recommended, simplest)
wav2vec2_embedding (768)
+
roberta_embedding (768)
â†“ concat
1536 â†’ classifier â†’ emotion


This is easy and very effective.

2ï¸âƒ£ Early fusion (advanced)

Fuse frame-level audio with token-level text â†’ more complex, not needed now.

Minimal multimodal forward pass (concept)
audio_emb = wav2vec2(input_values).last_hidden_state.mean(dim=1)
text_emb  = roberta(**text_inputs).last_hidden_state[:,0,:]

fused = torch.cat([audio_emb, text_emb], dim=-1)
logits = classifier(fused)

When should you use RoBERTa?

Use RoBERTa if:

âœ” You have transcriptions (you do)

âœ” You want higher performance

âœ” You want speaker-independent robustness

Do NOT use it if:

âŒ You want audio-only SER

âŒ You want very low latency inference

Expected gain (realistic)

On datasets like:

TESS

RAVDESS

CREMA-D

Typical gains:

+10â€“15% macro-F1

More stable across speakers

Summary (one sentence)

RoBERTa is a text encoder that lets your model understand what is being said, while Wav2Vec2 understands how itâ€™s said â€” combining both gives much better emotion recognition.